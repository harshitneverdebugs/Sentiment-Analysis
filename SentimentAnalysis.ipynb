{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ZoQOAH-pGA6X0TehSuvBWMAx8hRU6iWF",
      "authorship_tag": "ABX9TyM78BDq9CrZGzxyfNyWjDbY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshitneverdebugs/Sentiment-Analysis/blob/main/SentimentAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-kyk8Y6g5Qeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "id": "4S9l_3BP7EI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from numpy import array\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import one_hot, Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, Dense, Flatten, GlobalMaxPooling1D, Embedding, Conv1D, LSTM\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "C2tnKgeo5R5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/IMDB Dataset.csv\")"
      ],
      "metadata": {
        "id": "AqgLuWj26nEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "9tW_dKut7Wew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "ZHYLEfSL7YN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.countplot(x='sentiment', data=df)"
      ],
      "metadata": {
        "id": "apb0ocfR8iel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TAG_RE = re.compile(r'<[^>]+>')\n",
        "\n",
        "def remove_tags(text):\n",
        "    '''Removes HTML tags: replaces anything between opening and closing <> with empty space'''\n",
        "    return TAG_RE.sub('', text)"
      ],
      "metadata": {
        "id": "ZdrEcv6l8xaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "-j_Avovb91H-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(sen):\n",
        "\n",
        "    sentence = sen.lower()\n",
        "    sentence = remove_tags(sentence)\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "    pattern = re.compile(r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*')\n",
        "    sentence = pattern.sub('', sentence)\n",
        "\n",
        "    return sentence\n"
      ],
      "metadata": {
        "id": "bkZtwYZw9UuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=[]\n",
        "sentences=list(df['review'])\n",
        "for sen in sentences:\n",
        "  X.append(preprocess_text(sen))"
      ],
      "metadata": {
        "id": "36qjkg659XVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[5]"
      ],
      "metadata": {
        "id": "muzvTWIA9syr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = df['sentiment']\n",
        "Y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, Y)))"
      ],
      "metadata": {
        "id": "xorPhm_u96Vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "bkDLs-nG-f8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenizer = Tokenizer()\n",
        "word_tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = word_tokenizer.texts_to_sequences(X_train)\n",
        "X_test = word_tokenizer.texts_to_sequences(X_test)"
      ],
      "metadata": {
        "id": "bl7oOEtg-viD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_length = len(word_tokenizer.word_index) + 1\n",
        "vocab_length"
      ],
      "metadata": {
        "id": "2nOyS0iq_cd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen=100\n",
        "X_train=pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test=pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "metadata": {
        "id": "CSv7nbAWAAde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "metadata": {
        "id": "zhNkoipVGp4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip glove*.zip"
      ],
      "metadata": {
        "id": "mDQbKKz1GsY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "!pwd"
      ],
      "metadata": {
        "id": "r9hL4sLvGuv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "embeddings_dictionary=dict()\n",
        "glove_file = open('glove.6B.100d.txt', encoding=\"utf8\")\n",
        "\n",
        "for line in glove_file:\n",
        "  records=line.split()\n",
        "  word=records[0]\n",
        "  vector_dimensions=asarray(records[1:], dtype='float32')\n",
        "  embeddings_dictionary[word]=vector_dimensions\n",
        "glove_file.close()"
      ],
      "metadata": {
        "id": "gtEzLuW6BjH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix=zeros((vocab_length, 100))\n",
        "for word, index in word_tokenizer.word_index.items():\n",
        "  embedding_vector=embeddings_dictionary.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[index]=embedding_vector"
      ],
      "metadata": {
        "id": "iQMHpC9pD7MS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix.shape"
      ],
      "metadata": {
        "id": "ve4OW0eeIcqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple Neural Network"
      ],
      "metadata": {
        "id": "LqWH8bNXTzn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "snn_model = Sequential()\n",
        "embedding_layer = Embedding(vocab_length, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
        "snn_model.add(embedding_layer)\n",
        "snn_model.add(Flatten())\n",
        "snn_model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "4jQk3a3NI1rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "snn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "print(snn_model.summary())"
      ],
      "metadata": {
        "id": "2mgbPH7wO6Yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "snn_model_history=snn_model.fit(X_train, Y_train, batch_size=128, epochs=6, verbose=1, validation_split=0.2)"
      ],
      "metadata": {
        "id": "al9s2dK6QSPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score=snn_model.evaluate(X_test, Y_test, verbose=1)"
      ],
      "metadata": {
        "id": "f7h1hy42Q84o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test score:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "metadata": {
        "id": "YknC0xHhRcHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(snn_model_history.history['acc'])\n",
        "plt.plot(snn_model_history.history['val_acc'])\n",
        "\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(snn_model_history.history['loss'])\n",
        "plt.plot(snn_model_history.history['val_loss'])\n",
        "\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lO_iOm6ORns8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolutional Neural Network"
      ],
      "metadata": {
        "id": "mqKG6YHDT_-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv1D"
      ],
      "metadata": {
        "id": "bEWXOO_PRvRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = Sequential()\n",
        "embedding_layer = Embedding(vocab_length, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
        "cnn_model.add(embedding_layer)\n",
        "cnn_model.add(Conv1D(128, 5, activation='relu'))\n",
        "cnn_model.add(GlobalMaxPooling1D())\n",
        "cnn_model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "szCUWLGSSKnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "W0aH0cLpTr_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "print(cnn_model.summary())"
      ],
      "metadata": {
        "id": "HBq83VtRSamB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model_history = cnn_model.fit(X_train, Y_train, batch_size=128, epochs=6, verbose=1, validation_split=0.2)"
      ],
      "metadata": {
        "id": "C7ITt8EcStxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = cnn_model.evaluate(X_test, Y_test, verbose=1)"
      ],
      "metadata": {
        "id": "5m03fttESc0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test Score:\", score[0])\n",
        "print(\"Test Accuracy:\", score[1])"
      ],
      "metadata": {
        "id": "13968b_3Se3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(cnn_model_history.history['acc'])\n",
        "plt.plot(cnn_model_history.history['val_acc'])\n",
        "\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(cnn_model_history.history['loss'])\n",
        "plt.plot(cnn_model_history.history['val_loss'])\n",
        "\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc = 'upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dcRXeM5_SjBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reccurent Neural Network(LSTM)"
      ],
      "metadata": {
        "id": "p3qNqN7eUElO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model = Sequential()\n",
        "embedding_layer = Embedding(vocab_length, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
        "lstm_model.add(embedding_layer)\n",
        "lstm_model.add(LSTM(128))\n",
        "lstm_model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "6DiX-Hq2SnHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "print(lstm_model.summary())"
      ],
      "metadata": {
        "id": "I-hA_0k_UYmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model_history = lstm_model.fit(X_train, Y_train, batch_size=128, epochs=6, verbose=1, validation_split=0.2)"
      ],
      "metadata": {
        "id": "R1L7wJcqUaZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = lstm_model.evaluate(X_test, Y_test, verbose=1)"
      ],
      "metadata": {
        "id": "0qt7s3EWUc-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test Score:\", score[0])\n",
        "print(\"Test Accuracy:\", score[1])"
      ],
      "metadata": {
        "id": "5pSh_o1uUgOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(lstm_model_history.history['acc'])\n",
        "plt.plot(lstm_model_history.history['val_acc'])\n",
        "\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(lstm_model_history.history['loss'])\n",
        "plt.plot(lstm_model_history.history['val_loss'])\n",
        "\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "e8ruFeqxUhh3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}